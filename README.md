## Overview
In this project we examined the automatic seagrass coverage estimation of the sea bottom.
A total of **12682** images of the seabed at different depths along Croatia's Adriatic coast were taken with the help of a diving robot.
Of these, **6036** images were manually polygon-annotated by hand and made available to the public as pixel maps.
Using this dataset, we tested a superpixel classification of seagrass images. To achieve this, we used several different feature extraction methods as for example CNN-Features that turned out to be the best ones in our experiments.

This project is a joint work between *University of Zadar - Croatia* and *University of Applied Sciences Fulda - Germany*
### Envolved People
* Dr. Stewart T. Schultz, Zadar
* Dr. Claudia Kruschel, Zadar
* Dr. Viviane Wolff,  Fulda
* Dr. Klaus Fricke-Neuderth, Fulda
* Gereon Reus, Fulda
* Thomas Möller, Fulda
* Jonas Jäger, Fulda
* Julian Hasenauer, Fulda

### Paper

The full paper **Looking for Seagrass: Deep Learning for Visual Coverage Estimation (accepted for publication@IEEE - OCEANS 2018 Kobe)** is available at: [HS Fulda](https://www.hs-fulda.de/fileadmin/user_upload/FB_ET/Projekte_Forschung/Enview_Jaeger/EnView_News_2018-04/Conference_Kobe_2018_Seagrass.pdf)

## Dataset

[looking-for-seagrass-dataset](https://drive.google.com/open?id=1X0pmRIkPRC672_vuWqotfLdgbHx1QpFZ)

## Utils

## Experiments
### Deep Net for feature extraction
http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz
